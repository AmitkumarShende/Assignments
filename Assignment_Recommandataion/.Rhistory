train <- glass[ind==1,]
test <- glass[ind==2,]
train_labels<-glass[ind==1,10]
test_labels<-glass[ind==2,10]
# KNN Model
trcontrol <- trainControl(method = "repeatedcv", number = 10,repeats = 3)
#method = "repeatedcv", number = 10
#10-fold CV mean dividing your training dataset randomly into 10 parts
#and then using each of 10 parts as testing dataset for the model trained on other 9
#repeats: For repeated k-fold cross-validation only: the number of complete sets of folds to compute
set.seed(123)
fit <- train(Type ~., data = train, method = 'knn', tuneLength = 20,
trControl = trcontrol, preProc = c("center","scale"))
# default metric is accuracy but if u want to use ROC, then mention the same
# Model Performance :
fit # the optimum value for k is 5
#Plotting the data
plot(fit)
#Checking Variable Importance
varImp(fit)
pred <- predict(fit, newdata = test )
confusionMatrix(pred, test$Type)   # 68.42 % is accuracy
install.packages("caret")
library(caret)
# Read the dataset
zoo <- read.csv(file.choose())
View(zoo)
#View(zoo)
zoo <- zoo[,c(ncol(zoo),2:(ncol(zoo)-1))]
View(zoo)
# Read the dataset
zoo <- read.csv(file.choose())
#table of Type 1 <- 70 and 2 <- 76 .....Type 7 <-29
table(zoo$type)
View(zoo)
zoo_target <- zoo[, 18]
zoo_key <- zoo[, 1]
zoo_key
zoo$animal <- NULL
names(types) <- c("mammal", "bird", "reptile", "fish", "amphibian", "insect", "crustacean")
View(zoo)
summary(zoo)
str(zoo)
k = round(sqrt(18) )
k = round(sqrt(18) +1)
m1 <- knn.cv(zoo, zoo_target, k, prob = TRUE)
zoo1 <- zoo[,2:18]
View(zoo1)
str(zoo1)
zoo1[,con.names] = data.frame(apply(zoo1[con.names], 2, as.factor))
con.names = zoo1 %>% select_if(is.numeric) %>% colnames()
library(dplyr)
con.names = zoo1 %>% select_if(is.numeric) %>% colnames()
#con.names
zoo1[,con.names] = data.frame(apply(zoo1[con.names], 2, as.factor))
str(zoo1)
# Data partition
set.seed(123)
ind <- sample(2,nrow(zoo1), replace = T, prob = c(0.7,0.3))
train <- zoo1[ind==1,]
test <- zoo1[ind==2,]
trcontrol <- trainControl(method = "repeatedcv", number = 10,repeats = 3
# classprobs are needed when u want to select ROC for optimal K Value
)
set.seed(123)
fit <- train(type ~., data = train, method = 'knn', tuneLength = 20,
trControl = trcontrol, preProc = c("center","scale"))
# Default metric is accuracy but if u want to use ROC, then mention the same
# Model Performance :
fit # the optimum value for k should be 7
plot(fit)
varImp(fit)
pred <- predict(fit, newdata = test )
confusionMatrix(pred, test$type)
library(arules)
library(arulesViz)
Mymovies = read.csv("D:/Data_science/Assignments/Assignments_association/Assign_My_movies/my_movies.csv")
View(Mymovies)
Mymovies<-Mymovies[6:15]
View(Mymovies)
str(Mymovies)
rules <- apriori(as.matrix(Mymovies,parameter=list(support=0.2, confidence = 0.5,minlen=5)))
rules
inspect(head(sort(rules, by = "lift")))
head(quality(rules))
#devtools::install_github("jrowen/twitteR", ref = "oauth_httr_1_0")
library("twitteR")
#install.packages("ROAuth")
library("ROAuth") # Third party Anothitication with R
cred <- OAuthFactory$new(consumerKey='1g2jM8GbPTS485dGxT7qT6QLS', # Consumer Key (API Key)
consumerSecret='HZtdKswqrxOoHQ3mex1CtjEdVMq6x9dHFUhrf3cwrxtPJ53Pf2', #Consumer Secret (API Secret)
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
#cred$handshake(cainfo="cacert.pem")
save(cred, file="twitter authentication.Rdata") # credential
load("twitter authentication.Rdata")
#install.packages("base64enc")
library(base64enc) #encoding
#install.packages("httpuv")
library(httpuv) #Provides low-level socket and protocol support for handling HTTP and WebSocket requests directly from within R
setup_twitter_oauth("1g2jM8GbPTS485dGxT7qT6QLS", # Consumer Key (API Key)
"HZtdKswqrxOoHQ3mex1CtjEdVMq6x9dHFUhrf3cwrxtPJ53Pf2", #Consumer Secret (API Secret)
"268613265-Q3VqZ1MypXzzLbC4eYkH6Vmp0SS9TTjV3HNVP6ui",  # Access Token
"zxTHA9D7pxKFBGIQeLoG7PYEbobXTwVB6kcyRrNhqZs5o")  #Access Token Secret
Tweets <- userTimeline('SrBachchan', n = 1000,includeRts = T)
View(Tweets)
TweetsDF <- twListToDF(Tweets)
dim(TweetsDF)
View(TweetsDF)
Tweets <- userTimeline('PundanSingh', n = 1000,includeRts = T)
TweetsDF <- twListToDF(Tweets)
View(TweetsDF)
texttweet<-TweetsDF[,:1]
texttweet<-TweetsDF[,1]
getwd()
#write.csv(TweetsDF, "PundanSingh.csv",row.names = F)
write.csv(texttweet, "PundanSingh.csv",row.names = F)
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
View(salary_train)
##Training a model on the data ----
# begin by training a simple linear SVM
library(kernlab)
str(salary_train)
?dfrm
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
library(dplyr)
?dfrm
# Get column names
colnames(salary_train)
View(salary_train)
col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_train <- salary_train[, col_order]
View(salary_train)
salary_train1= data.frame(apply(salary_train[,9:14], 2, as.factor))
str(salary_train1)
salary_train2= (salary_train[,1:9])
salary_train=cbind(salary_train1,salary_train2 )
str(salary_train)
str(salary_train)
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
library(dplyr)
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
str(salary_train)
# Get column names
colnames(salary_train)
salary_train= data.frame(apply(salary_train, 2, as.factor))
str(salary_train)
col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_train <- salary_train[, col_order]
salary_train1= (salary_train[,9:14])
salary_train2= (salary_train[,1:9])
salary_train=cbind(salary_train1,salary_train2 )
str(salary_train)
View(salary_train)
##Training a model on the data ----
# begin by training a simple linear SVM
library(kernlab)
salary_classifier <- ksvm(Salary ~ ., data = salary_train,
kernel = "vanilladot")
salary_train2= (salary_train[,1:8])
salary_train=cbind(salary_train1,salary_train2 )
str(salary_train)
##Training a model on the data ----
# begin by training a simple linear SVM
library(kernlab)
salary_classifier <- ksvm(Salary ~ ., data = salary_train,
kernel = "vanilladot")
View(salary_train)
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
str(salary_train)
# Get column names and Rearrange the columns for model performance
colnames(salary_train)
salary_train= data.frame(apply(salary_train, 2, as.factor))
str(salary_train)
col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_train <- salary_train[, col_order]
salary_train1= (salary_train[,9:14])
View(salary_train1)
salary_train1= (salary_train[,10:14])
View(salary_train1)
salary_train2= (salary_train[,1:9])
View(salary_train2)
salary_train=cbind(salary_train2,salary_train1 )
View(salary_train)
##Training a model on the data ----
# begin by training a simple linear SVM
library(kernlab)
salary_classifier <- ksvm(Salary ~ ., data = salary_train,
kernel = "vanilladot")
salary_classifier
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
library(readr)
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
colnames(salary_test)
salary_test= data.frame(apply(salary_test, 2, as.factor))
str(salary_test)
col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_test <- salary_test[, col_order]
salary_test1= (salary_test[,10:14])
salary_test2= (salary_test[,1:9])
salary_test=cbind(salary_test2,salary_test1 )
str(salary_test)
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
salary_classifier <- ksvm(salary_train$Salary ~ ., data = salary_train,
kernel = "vanilladot")
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
library(readr)
library(dplyr)
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
str(salary_train)
# Get column names and Rearrange the columns for TRAIN model performance
colnames(salary_train)
salary_train= data.frame(apply(salary_train, 2, as.factor))
col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_train <- salary_train[, col_order]
str(salary_train)
colnames(salary_test)
salary_test= data.frame(apply(salary_test, 2, as.factor))
col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_test <- salary_test[, col_order]
str(salary_test)
##Training a model on the data ----
# begin by training a simple linear SVM
library(kernlab)
salary_classifier <- ksvm(salary_train$Salary ~ ., data = salary_train,
kernel = "vanilladot")
salary_classifier
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
library(readr)
library(dplyr)
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
str(salary_train)
# Get column names and Rearrange the columns for TRAIN model performance
colnames(salary_train)
salary_train[1:14]= data.frame(apply(salary_train[1:14], 2, as.factor))
#col_order <- c("Salary","native","workclass","education", "maritalstatus","occupation","relationship",
"race","sex","age","educationno","capitalgain","capitalloss","hoursperweek" )
salary_train[1:14]= data.frame(apply(salary_train[1:14], 2, as.factor))
#salary_train <- salary_train[, col_order]
str(salary_train)
# Get column names and Rearrange the columns for TEST model performance
colnames(salary_test)
salary_test[1:14]= data.frame(apply(salary_test[1:14], 2, as.factor))
#salary_test <- salary_test[, col_order]
str(salary_test)
##Training a model on the data ----
# begin by training a simple linear SVM
library(kernlab)
salary_classifier <- ksvm(salary_train$Salary ~ ., data = salary_train,
kernel = "vanilladot")
salary_classifier
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
#####Support Vector Machines -------------------
##  Optical Character Recognition ----
#load salarydata as salary
# divide into training and test data
library(readr)
library(dplyr)
library(kernlab)
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
str(salary_train)
# Get column names and Rearrange the columns for TRAIN model performance
salary_train$educationno <- as.factor(salary_train$educationno)
salary_test$educationno <- as.factor(salary_test$educationno)
#salary_train <- salary_train[, col_order]
str(salary_train)
#salary_test <- salary_test[, col_order]
str(salary_test)
salary_classifier <- ksvm(salary_train$Salary ~ ., data = salary_train,
kernel = "vanilladot")
salary_classifier
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
head(salary_predictions)
table(salary_predictions, salary_test$salary)
table(salary_predictions, salary_test$salary)
table(salary_predictions, salary_test$Salary)
agreement <- salary_predictions == salary_test$Salary
table(agreement)
prop.table(table(agreement))
## Improving model performance ----
salary_classifier_rbf <- ksvm(Salary ~ ., data = salary_train, kernel = "rbfdot")
salary_predictions_rbf <- predict(salary_classifier_rbf, salary_test)
agreement_rbf <- salary_predictions_rbf == salary_test$Salary
table(agreement_rbf)
prop.table(table(agreement_rbf))
?ksvm
## Improving model performance ----polydot
salary_classifier_polydot <- ksvm(Salary ~ ., data = salary_train, kernel = "polydot")
# predictions on testing dataset
salary_predictions_polydot <- predict(salary_classifier_polydot, salary_test)
agreement_polydot <- salary_predictions_polydot == salary_test$Salary
table(agreement_polydot)
prop.table(table(agreement_polydot))
library(caret)
library(ggplot2)
#Visualization
# Plot and ggplot
ggplot(data=salary_train,aes(x=salary_train$Salary, y = salary_train$age, fill = salary_train$Salary)) +
geom_boxplot() +
ggtitle("Box Plot")
plot(salary_train$workclass,salary_train$Salary)
plot(salary_train$maritalstatus,salary_train$Salary)
ggplot(data=salary_train,aes(x = salary_train$age, fill = salary_train$Salary)) +
geom_density(alpha = 0.9, color = 'Violet')
ggtitle("Age - Density Plot") #  graph Heading
ggplot(data=salary_train,aes(x = salary_train$age, fill = salary_train$Salary)) +
geom_density(alpha = 0.9, color = 'Violet')+ ggtitle("Age - Density Plot") #  graph Heading
ggplot(data=salary_train,aes(x = salary_train$workclass, fill = salary_train$Salary)) +
geom_density(alpha = 0.9, color = 'Violet')+ggtitle("Age - Density Plot") #  graph Heading
# Get into factor form to TRAIN model performance
con.names = salary_train %>% select_if(is.numeric) %>% colnames()
con.names
con.names =columns(salary_train)
con.names =colnames(salary_train, do.NULL = TRUE, prefix = "col")
# Get into factor form to TRAIN model performance
col.names =colnames(salary_train, do.NULL = TRUE, prefix = "col")
col.names
#####Support Vector Machines -------------------
library(readr)
library(dplyr)
library(kernlab)
library(caret)
library(ggplot2)
salary_train= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Train.csv")
salary_test= read.csv("D:/Data_science/Assignments/Assignment_SVM/SalaryData_Test.csv")
str(salary_train)
# Get into factor form to TRAIN model performance
col.names =colnames(salary_train, do.NULL = TRUE, prefix = "col")
salary_train$educationno <- as.factor(salary_train$educationno)
salary_test$educationno <- as.factor(salary_test$educationno)
str(salary_train)
str(salary_test)
#Visualization OR EDA
# Plot and ggplot
ggplot(data=salary_train,aes(x=salary_train$Salary, y = salary_train$age, fill = salary_train$Salary)) +
geom_boxplot() +
ggtitle("Box Plot")
plot(salary_train$workclass,salary_train$Salary)
plot(salary_train$maritalstatus,salary_train$Salary)
ggplot(data=salary_train,aes(x = salary_train$age, fill = salary_train$Salary)) +
geom_density(alpha = 0.9, color = 'Violet')+ ggtitle("Age - Density Plot") #  graph Heading
ggplot(data=salary_train,aes(x = salary_train$workclass, fill = salary_train$Salary)) +
geom_density(alpha = 0.9, color = 'Violet')+ggtitle("Age - Density Plot") #  graph Heading
ggplot(data=salary_train,aes(x = salary_train$workclass, fill = salary_train$Salary)) +
geom_density(alpha = 0.9, color = 'Violet')+ggtitle("workclass - Density Plot") #  graph Heading
salary_classifier <- ksvm(salary_train$Salary ~ ., data = salary_train,
kernel = "vanilladot")
salary_classifier
## Evaluating model performance ----
# predictions on testing dataset
salary_predictions <- predict(salary_classifier, salary_test)
head(salary_predictions)
table(salary_predictions, salary_test$Salary)
agreement <- salary_predictions == salary_test$Salary
table(agreement)
prop.table(table(agreement))
## Improving model performance ----rbfdot
salary_classifier_rbf <- ksvm(Salary ~ ., data = salary_train, kernel = "rbfdot")
salary_predictions_rbf <- predict(salary_classifier_rbf, salary_test)
agreement_rbf <- salary_predictions_rbf == salary_test$Salary
table(agreement_rbf)
prop.table(table(agreement_rbf))
## Improving model performance ----polydot
salary_classifier_polydot <- ksvm(Salary ~ ., data = salary_train, kernel = "polydot")
salary_predictions_polydot <- predict(salary_classifier_polydot, salary_test)
agreement_polydot <- salary_predictions_polydot == salary_test$Salary
table(agreement_polydot)
prop.table(table(agreement_polydot))
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_SVM/forestfires.csv")
str(ForestFire)
class(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire$temp = normalize(ForestFire$temp)
ForestFire$RH   = normalize(ForestFire$RH)
ForestFire$wind = normalize(ForestFire$wind)
ForestFire$rain = normalize(ForestFire$rain)
# Data Partition
set.seed(123)
ind <- sample(2, nrow(FF), replace = TRUE, prob = c(0.7,0.3))
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
library(e1071)
model1<-ksvm(size_category~temp+rain+wind+RH,
data= FF_train,kernel = "vanilladot")
model1
Area_pred <- predict(model1, FF_test)
table(Area_pred,FF_test$size_category)
agreement <- Area_pred == FF_test$size_category
table(agreement)
prop.table(table(agreement))
# kernel = rfdot
model_rfdot<-ksvm(size_category~temp+rain+wind+RH,
data= FF_train,kernel = "rbfdot")
pred_rfdot<-predict(model_rfdot,newdata=FF_test)
mean(pred_rfdot==FF_test$size_category) # 68.41
mean(Area_pred==FF_test$size_category)
model_poly<-ksvm(size_category~temp+rain+wind+RH,
data= FF_train,kernel = "polydot")
pred_poly<-predict(model_poly,newdata = FF_test)
mean(pred_poly==FF_test$size_category) # 67.80
mba <- read.csv("E:/Datasets/Datasets_BA 2/mba.csv")
mba <- read.csv("D:/Data_science/R/csv_files/mba.csv")
mba <- read.csv("D:/Data_science/R/csv_files/mba.csv")
View(mba)
#mode
getmode <- function(x){
uniquv <- unique(x)
uniquv[which.max(tabulate(match(x,uniquv)))]
}
getmode(mba$gmat)
library(recommenderlab)
library(dplyr)
library(caTools)
library(reshape2)
library(Matrix)
library(data.table)
setwd("D:/Data_science/Assignments/Assignment_Recommandataion")
#book rating data
book_rate_data <- read.csv("D:/Data_science/Assignments/Assignment_Recommandataion/books.csv")
book_rate_data <- book_rate_data[2:6]
names(book_rate_data)[1]<-"users" #.....[1]--column number, "retings"----name to change for R
names(book_rate_data)[5]<-"ratings" #.....[1]--column number, "retings"----name to change for R
names(book_rate_data)[2]<-"bookname" #.....[1]--column number, "retings"----name to change for R
names(book_rate_data)[3]<-"author" #.....[1]--column number, "retings"-
#book rating data
book_rate_data <- read.csv("D:/Data_science/Assignments/Assignment_Recommandataion/books.csv", header=TRUE)
head(book_rate_data)
book_rate_data <- book_rate_data[,-c(1)]
View(book_rate_data)
names(book_rate_data)[1]<-"users" #.....[1]--column number, "retings"----name to change for R
names(book_rate_data)[5]<-"ratings" #.....[1]--column number, "retings"----name to change for R
names(book_rate_data)[2]<-"bookname" #.....[1]--column number, "retings"----name to change for R
names(book_rate_data)[3]<-"author" #.....[1]--column number, "retings"----name to change for R
book_rate_data-g<-acast(book_rate_data, bookname~ratings)
book_rate_data_g<-acast(book_rate_data, bookname ~ ratings)
class(book_rate_data_g)
book_rate_dataM<-as.matrix(book_rate_data_g)
#rating distribution
hist(book_rate_dataM$ratings)
#rating distribution
hist(book_rate_data$ratings)
## covert to matrix format
#book_rate_data_matrix <- as.matrix(acast(book_rate_data, bookname~author, fun.aggregate = mean, value.var = "ratings"))
dim(book_rate_dataM)
#the datatype should be realRatingMatrix inorder to build recommendation of books
book_rate_data_matrix <- as(book_rate_dataM, 'realRatingMatrix')
book_rate_data_matrix
as(book_rate_data_matrix, "list")
as(book_rate_data_matrix, "matrix")
#turn in to data frames
head(as(book_rate_data_matrix, "dataframe"))
library(ggplot2)
library(recommenderlab)
library(dplyr)
library(caTools)
library(reshape2)
library(Matrix)
library(data.table)
library(ggplot2)
setwd("D:/Data_science/Assignments/Assignment_Recommandataion")
#book rating data
book_rate_data <- read.csv("D:/Data_science/Assignments/Assignment_Recommandataion/books.csv", header=TRUE)
