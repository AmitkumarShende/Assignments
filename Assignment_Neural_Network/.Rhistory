plot(concrete_model)
set.seed(12323)
model_results <- compute(concrete_model,test[1:8])
str(model_results)
predicted_strength <- model_results$net.result
cor(predicted_strength,concrete_test$strength)
cor(predicted_strength,test$strength)
plot(predicted_strength,test$strength)
## Improving model performance ----
# a more complex neural network topology with 5 hidden neurons
model2 <- neuralnet(strength ~ cement + slag
+ ash + water + superplastic
+ coarseagg + fineagg + age, data = train, hidden = 10)
model2 <- neuralnet(strength ~ cement + slag
+ ash + water + superplastic
+ coarseagg + fineagg + age, data = train, hidden = 5)
model2
# plot the network
plot(model2)
# evaluate the results as we did before
model_results2 <- compute(model2, test[1:8])
library(neuralnet)  # regression
library(nnet) # classification
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
concrete <- read.csv(file.choose())
startup50 <- read.csv(file.choose())
View(startup50)
startup50 <- read.csv(file.choose())
View(startup50)
startup50 <- read.csv(file.choose())
View(startup50)
str(startup50)
return ( (x-min(x))/(max(x)-min(x)))
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
View(startup50)
library(neuralnet)  # regression
library(nnet) # classification
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
startup50 <- read.csv(file.choose())
View(startup50)
str(startup50)
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
startup50_norm<-as.data.frame(lapply(startup50[,-3],FUN=normalize))
class(startup50)
startup50$State <- as.numeric(revalue(startup50$State,
c("New York"="0", "California"="1",
"Florida"="2")))
library(plyr)
startup50$State <- as.numeric(revalue(startup50$State,
c("New York"="0", "California"="1",
"Florida"="2")))
str(startup50)
Startups <- read.csv(file.choose())
View(Startups)
str(Startups)
class(Startups)
Startups$State <- as.numeric(revalue(Startups$State,
c("New York"="0", "California"="1",
"Florida"="2")))
str(Startups)
Startups <- as.data.frame(Startups)
attach(Startups)
plot(R.D.Spend, Profit)
plot(Administration, Profit)
plot(Marketing.Spend, Profit)
plot(State, Profit)
windows()
# Find the correlation between Output (Profit) & inputs (R.D Spend, Administration, Marketing, State) - SCATTER DIAGRAM
pairs(Startups)
# Correlation coefficient - Strength & Direction of correlation
cor(Startups)
summary(Startups) # Confirms on the different scale and demands normalizing the data.
Startups_norm<-as.data.frame(lapply(Startups,FUN=normalize))
Startups_norm<-as.data.frame(lapply(Startups,FUN=normalize))
Startups_norm<-as.data.frame(lapply(Startups,FUN=normalize))
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
Startups_norm<-as.data.frame(lapply(Startups,FUN=normalize))
summary(Startups_norm$Profit) # Normalized form of profit
summary(Startups$profit) # Orginal profit value
ind <- sample(2, nrow(Startups_norm), replace = TRUE, prob = c(0.7,0.3))
Startups_train <- Startups_norm[ind==1,]
startups_test  <- Startups_norm[ind==2,]
startups_model <- neuralnet(Profit~R.D.Spend+Administration
+Marketing.Spend+State,data = Startups_train)
str(startups_model)
plot(startups_model, rep = "best")
summary(startups_model)
par(mar = numeric(4), family = 'serif')
plotnet(startups_model, alpha = 0.6)
library(NeuralNetTools)
install.packages("NeuralNetTools")
library(NeuralNetTools)
plotnet(startups_model, alpha = 0.6)
model_results <- compute(startups_model,startups_test[1:4])
predicted_profit <- model_results$net.result
# Predicted profit Vs Actual profit of test data.
cor(predicted_profit,startups_test$Profit)
# since the prediction is in Normalized form, we need to de-normalize it
# to get the actual prediction on profit
str_max <- max(Startups$Profit)
str_min <- min(Startups$Profit)
unnormalize <- function(x, min, max) {
return( (max - min)*x + min )
}
ActualProfit_pred <- unnormalize(predicted_profit,str_min,str_max)
head(ActualProfit_pred)
set.seed(12345)
Startups_model2 <- neuralnet(Profit~R.D.Spend+Administration
+Marketing.Spend+State,data = Startups_train,
hidden = 2)
plot(Startups_model2 ,rep = "best")
summary(Startups_model2)
model_results2<-compute(Startups_model2,startups_test[1:4])
predicted_Profit2<-model_results2$net.result
cor(predicted_Profit2,startups_test$Profit)
plot(predicted_Profit2,startups_test$Profit)
par(mar = numeric(4), family = 'serif')
plotnet(Startups_model2, alpha = 0.6)
library(NeuralNetTools)
library(neuralnet)  # regression
library(nnet) # classification
library(plyr)
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
Startups <- read.csv(file.choose())
View(Startups)
str(Startups)
class(Startups)
Startups$State <- as.numeric(revalue(Startups$State,
c("New York"="0", "California"="1",
"Florida"="2")))
str(Startups)
Startups <- as.data.frame(Startups)
attach(Startups)
plot(R.D.Spend, Profit)
plot(Administration, Profit)
plot(Marketing.Spend, Profit)
plot(State, Profit)
windows()
# Find the correlation between Output (Profit) & inputs (R.D Spend, Administration, Marketing, State) - SCATTER DIAGRAM
pairs(Startups)
# Correlation coefficient - Strength & Direction of correlation
cor(Startups)
summary(Startups) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
Startups_norm<-as.data.frame(lapply(Startups,FUN=normalize))
summary(Startups_norm$Profit) # Normalized form of profit
summary(Startups$profit) # Orginal profit value
# Data Partition
set.seed(123)
ind <- sample(2, nrow(Startups_norm), replace = TRUE, prob = c(0.7,0.3))
Startups_train <- Startups_norm[ind==1,]
startups_test  <- Startups_norm[ind==2,]
startups_model <- neuralnet(Profit~R.D.Spend+Administration
+Marketing.Spend+State,data = Startups_train)
str(startups_model)
plot(startups_model, rep = "best")
summary(startups_model)
windows()
par(mar = numeric(4), family = 'serif')
plotnet(startups_model, alpha = 0.6)
model_results <- compute(startups_model,startups_test[1:4])
predicted_profit <- model_results$net.result
# Predicted profit Vs Actual profit of test data.
cor(predicted_profit,startups_test$Profit)
# since the prediction is in Normalized form, we need to de-normalize it
# to get the actual prediction on profit
str_max <- max(Startups$Profit)
str_min <- min(Startups$Profit)
unnormalize <- function(x, min, max) {
return( (max - min)*x + min )
}
ActualProfit_pred <- unnormalize(predicted_profit,str_min,str_max)
head(ActualProfit_pred)
set.seed(12345)
Startups_model2 <- neuralnet(Profit~R.D.Spend+Administration
+Marketing.Spend+State,data = Startups_train,
hidden = 2)
plot(Startups_model2 ,rep = "best")
summary(Startups_model2)
model_results2<-compute(Startups_model2,startups_test[1:4])
predicted_Profit2<-model_results2$net.result
cor(predicted_Profit2,startups_test$Profit)
plot(predicted_Profit2,startups_test$Profit)
par(mar = numeric(4), family = 'serif')
plotnet(Startups_model2, alpha = 0.6)
library(NeuralNetTools)
hist(concrete$cement, prob = T, breaks = 30)
concrete <- read.csv(file.choose())
hist(concrete$cement, prob = T, breaks = 30)
lines(density(concrete$cement))
hist(concrete$slag, prob = T, breaks = 30)
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
concrete <- read.csv(file.choose())
hist(concrete$cement, prob = T, breaks = 30)
lines(density(concrete$cement))
hist(concrete$slag, prob = T, breaks = 30)
lines(density(concrete$slag))
FF <- read.csv(file.choose())
View(FF)
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_SVM/forestfires.csv")
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire$temp = normalize(ForestFire$temp)
ForestFire$RH   = normalize(ForestFire$RH)
ForestFire$wind = normalize(ForestFire$wind)
ForestFire$rain = normalize(ForestFire$rain)
# Data Partition
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
View(ForestFire)
names(ForestFire)[11]<-"Burned-area" #.....[1]--column number, "premium"----name to change for R
View(ForestFire)
View(ForestFire)
plot(temp, Burned-area)
plot(ForestFire$temp, ForestFire$Burned-area)
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
names(ForestFire)[11]<-"Burned-area" #.....[1]--column number, "Burned-area"----name to change for R
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire$temp = normalize(ForestFire$temp)
ForestFire$RH   = normalize(ForestFire$RH)
ForestFire$wind = normalize(ForestFire$wind)
ForestFire$rain = normalize(ForestFire$rain)
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
# Find the correlation between Output (Profit) & inputs (R.D Spend, Administration, Marketing, State) - SCATTER DIAGRAM
pairs(ForestFire)
# Find the correlation between Output (Profit) & inputs (R.D Spend, Administration, Marketing, State) - SCATTER DIAGRAM
pairs(ForestFire)
# Correlation coefficient - Strength & Direction of correlation
cor(Startups)
summary(Startups) # Confirms on the different scale and demands normalizing the data.
# Correlation coefficient - Strength & Direction of correlation
cor(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire-norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
FF_model <- neuralnet(Burned-area~temp+RH
+wind+rain,data = FF_train)
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
names(ForestFire)[11]<-"Burned_area" #.....[1]--column number, "Burned-area"----name to change for R
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire$temp = normalize(ForestFire$temp)
ForestFire$RH   = normalize(ForestFire$RH)
ForestFire$wind = normalize(ForestFire$wind)
ForestFire$rain = normalize(ForestFire$rain)
# Data Partition
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
FF_model <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train)
str(FF_model)
plot(FF_model, rep = "best")
attributes(FF_model)
# visualize the network topology
plot(FF_model)
ForestFire<-ForestFire[,2:30]
View(ForestFire)
ForestFire<-ForestFire[,3:30]
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
names(ForestFire)[11]<-"Burned_area" #.....[1]--column number, "Burned-area"----name to change for R
ForestFire<-ForestFire[,3:30]
View(ForestFire)
class(ForestFire) # As Dataframe
str(ForestFire)
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
View(ForestFire)
names(ForestFire)[11]<-"Burned_area" #.....[1]--column number, "Burned-area"----name to change for R
ForestFire<-ForestFire[,3:11]
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
ForestFire_norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
ForestFire_norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire_norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
FF_model <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train)
str(FF_model)
attributes(FF_model)
# visualize the network topology
plot(FF_model)
plot(FF_model, rep = "best")
summary(startups_model)
summary(FF_model)
windows()
par(mar = numeric(4), family = 'serif')
plotnet(FF_model, alpha = 0.6)
model_results <- compute(FF_model,test[1:9])
model_results <- compute(FF_model,FF_test[1:9])
predicted_profit <- model_results$net.result
predicted_Burned_area <- model_results$net.result
# Predicted Burned_area Vs Actual Burned_area of test data.
cor(predicted_Burned_area,FF_test$Burned_area)
# since the prediction is in Normalized form, we need to de-normalize it
# to get the actual prediction on profit
str_max <- max(ForestFire$Burned_area)
str_min <- min(ForestFire$Burned_area)
unnormalize <- function(x, min, max) {
return( (max - min)*x + min )
}
ActualBurned_area_pred <- unnormalize(predicted_Burned_area,str_min,str_max)
head(ActualBurned_area_pred)
set.seed(12345)
ForestFire_model2 <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train, hidden = 2)
plot(ForestFire_model2 ,rep = "best")
summary(ForestFire_model2)
model_results2<-compute(ForestFire_model2,FF_test[1:9])
predicted_Burned_area2<-model_results2$net.result
cor(predicted_Burned_area2,FF_test$Profit)
cor(predicted_Burned_area2,FF_test$Burned_area)
plot(predicted_Burned_area2,FF_test$Burned_area)
plotnet(Startups_model2, alpha = 0.6)
plotnet(ForestFire_model2, alpha = 0.6)
library(NeuralNetTools)
library(NeuralNetTools)
library(neuralnet)  # regression
library(nnet) # classification
library(plyr)
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
names(ForestFire)[11]<-"Burned_area" #.....[1]--column number, "Burned-area"----name to change for R
ForestFire<-ForestFire[,3:11]
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire_norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
# Data Partition
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
FF_model <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train)
str(FF_model)
attributes(FF_model)
# visualize the network topology
plot(FF_model)
plot(FF_model, rep = "best")
summary(FF_model)
windows()
par(mar = numeric(4), family = 'serif')
plotnet(FF_model, alpha = 0.6)
windows()
par(mar = numeric(4), family = 'serif')
plotnet(FF_model, alpha = 0.6)
model_results <- compute(FF_model,FF_test[1:9])
predicted_Burned_area <- model_results$net.result
# Predicted Burned_area Vs Actual Burned_area of test data.
cor(predicted_Burned_area,FF_test$Burned_area)
# since the prediction is in Normalized form, we need to de-normalize it
# to get the actual prediction on profit
str_max <- max(ForestFire$Burned_area)
str_min <- min(ForestFire$Burned_area)
unnormalize <- function(x, min, max) {
return( (max - min)*x + min )
}
ActualBurned_area_pred <- unnormalize(predicted_Burned_area,str_min,str_max)
head(ActualBurned_area_pred)
set.seed(12345)
ForestFire_model2 <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train, hidden = 2)
plot(ForestFire_model2 ,rep = "best")
summary(ForestFire_model2)
model_results2<-compute(ForestFire_model2,FF_test[1:9])
predicted_Burned_area2<-model_results2$net.result
cor(predicted_Burned_area2,FF_test$Burned_area)
plot(predicted_Burned_area2,FF_test$Burned_area)
View(FF_test)
View(FF_train)
par(mar = numeric(4), family = 'serif')
plotnet(ForestFire_model2, alpha = 0.6)
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
names(ForestFire)[11]<-"Burned_area" #.....[1]--column number, "Burned-area"----name to change for R
ForestFire<-ForestFire[,7:11]
View(ForestFire)
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire_norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
# Data Partition
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
FF_model <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train)
str(FF_model)
attributes(FF_model)
# visualize the network topology
plot(FF_model)
plot(FF_model, rep = "best")
summary(FF_model)
windows()
par(mar = numeric(4), family = 'serif')
plotnet(FF_model, alpha = 0.6)
model_results <- compute(FF_model,FF_test[1:9])
model_results <- compute(FF_model,FF_test[1:5])
predicted_Burned_area <- model_results$net.result
# since the prediction is in Normalized form, we need to de-normalize it
# to get the actual prediction on profit
str_max <- max(ForestFire$Burned_area)
str_min <- min(ForestFire$Burned_area)
set.seed(12345)
ForestFire_model2 <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train, hidden = 2)
plot(ForestFire_model2 ,rep = "best")
model_results2<-compute(ForestFire_model2,FF_test[1:5])
predicted_Burned_area2<-model_results2$net.result
plot(predicted_Burned_area2,FF_test$Burned_area)
par(mar = numeric(4), family = 'serif')
plotnet(ForestFire_model2, alpha = 0.6)
library(NeuralNetTools)
library(neuralnet)  # regression
library(nnet) # classification
library(plyr)
setwd("D:/Data_science/Assignments/Assignment_Neural_Network")
ForestFire= read.csv("D:/Data_science/Assignments/Assignment_Neural_Network/forestfires.csv")
names(ForestFire)[11]<-"Burned_area" #.....[1]--column number, "Burned-area"----name to change for R
ForestFire<-ForestFire[,7:11]
class(ForestFire) # As Dataframe
str(ForestFire)
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
# Prediction of Forest fires requires only prediction from
# temperature, rain, relative humidity and wind speed
# Apply Normalization technique to the whole dataset :
normalize<-function(x){
return ( (x-min(x))/(max(x)-min(x)))
}
ForestFire_norm<-as.data.frame(lapply(ForestFire,FUN=normalize))
# We need to tweak this as a classification problem.lets base out the Size using this criteria :
# Data Partition
set.seed(123)
ind <- sample(2, nrow(ForestFire), replace = TRUE, prob = c(0.7,0.3))
FF_train <- ForestFire[ind==1,]
FF_test  <- ForestFire[ind==2,]
summary(ForestFire) # Confirms on the different scale and demands normalizing the data.
# Creating a neural network model on training data
FF_model <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train)
str(FF_model)
attributes(FF_model)
# visualize the network topology
plot(FF_model)
plot(FF_model, rep = "best")
summary(FF_model)
windows()
par(mar = numeric(4), family = 'serif')
plotnet(FF_model, alpha = 0.6)
model_results <- compute(FF_model,FF_test[1:5])
predicted_Burned_area <- model_results$net.result
# since the prediction is in Normalized form, we need to de-normalize it
# to get the actual prediction on profit
str_max <- max(ForestFire$Burned_area)
str_min <- min(ForestFire$Burned_area)
set.seed(12345)
ForestFire_model2 <- neuralnet(Burned_area~temp+RH
+wind+rain,data = FF_train, hidden = 2)
plot(ForestFire_model2 ,rep = "best")
summary(ForestFire_model2)
model_results2<-compute(ForestFire_model2,FF_test[1:5])
predicted_Burned_area2<-model_results2$net.result
# Predicted Burned_area Vs Actual Burned_area of test data.
cor(predicted_Burned_area,FF_test$Burned_area)
